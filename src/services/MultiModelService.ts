export interface AIModel {
  id: string;
  name: string;
  provider: string;
  apiKey?: string;
  baseUrl?: string;
  maxTokens: number;
  temperature: number;
  priority: number;
  isAvailable: boolean;
  lastUsed: number;
  successRate: number;
  avgResponseTime: number;
}

export interface ModelResponse {
  success: boolean;
  response: string;
  model: string;
  provider: string;
  responseTime: number;
  tokensUsed?: number;
  error?: string;
}

export class MultiModelService {
  private models: AIModel[] = [
    {
      id: 'gemini-1.5-flash',
      name: 'Gemini 1.5 Flash',
      provider: 'google',
      maxTokens: 2048, // Giáº£m tá»« 8192 xuá»‘ng 2048 Ä‘á»ƒ nhanh hÆ¡n
      temperature: 0.1,
      priority: 1, // Æ¯u tiÃªn cao nháº¥t vÃ¬ nhanh nháº¥t
      isAvailable: true,
      lastUsed: 0,
      successRate: 0.88,
      avgResponseTime: 1200
    },
    {
      id: 'gpt-3.5-turbo',
      name: 'GPT-3.5 Turbo',
      provider: 'openai',
      maxTokens: 2048, // Giáº£m tá»« 4096 xuá»‘ng 2048 Ä‘á»ƒ nhanh hÆ¡n
      temperature: 0.1,
      priority: 2, // Æ¯u tiÃªn thá»© 2 vÃ¬ nhanh
      isAvailable: true,
      lastUsed: 0,
      successRate: 0.90,
      avgResponseTime: 1500
    },
    {
      id: 'deepseek-chat',
      name: 'DeepSeek Chat',
      provider: 'deepseek',
      maxTokens: 4096,
      temperature: 0.1,
      priority: 3, // Æ¯u tiÃªn thá»© 3 - cháº¥t lÆ°á»£ng cao
      isAvailable: true,
      lastUsed: 0,
      successRate: 0.93,
      avgResponseTime: 1800
    },
    {
      id: 'gpt-4o-mini',
      name: 'GPT-4o Mini',
      provider: 'openai',
      maxTokens: 2048, // Giáº£m tá»« 4096 xuá»‘ng 2048 Ä‘á»ƒ nhanh hÆ¡n
      temperature: 0.1,
      priority: 4, // Æ¯u tiÃªn thá»© 4 vÃ¬ cháº­m hÆ¡n
      isAvailable: true,
      lastUsed: 0,
      successRate: 0.95,
      avgResponseTime: 2000
    },
    {
      id: 'gemini-1.5-pro',
      name: 'Gemini 1.5 Pro',
      provider: 'google',
      maxTokens: 4096, // Giáº£m tá»« 32768 xuá»‘ng 4096 Ä‘á»ƒ nhanh hÆ¡n
      temperature: 0.1,
      priority: 5, // Æ¯u tiÃªn thá»© 5 vÃ¬ cháº­m nháº¥t
      isAvailable: true,
      lastUsed: 0,
      successRate: 0.92,
      avgResponseTime: 3000
    },
    {
      id: 'grok',
      name: 'Grok (xAI)',
      provider: 'xai',
      maxTokens: 8192,
      temperature: 0.1,
      priority: 6, // Æ¯u tiÃªn tháº¥p nháº¥t - real-time updates
      isAvailable: true,
      lastUsed: 0,
      successRate: 0.89,
      avgResponseTime: 2500
    }
  ];

  private currentModelIndex = 0;
  private retryCount = 0;
  private maxRetries = 3;

  constructor() {
    this.loadModelConfigs();
  }

  private loadModelConfigs() {
    const openaiKey = process.env.NEXT_PUBLIC_OPENAI_API_KEY || process.env.OPENAI_API_KEY;
    const googleKey = process.env.NEXT_PUBLIC_GOOGLE_API_KEY || process.env.GOOGLE_API_KEY;
    
    console.log('ğŸ” Checking API Keys...');
    console.log('OpenAI Key available:', !!openaiKey);
    console.log('Google Key available:', !!googleKey);
    
    if (!openaiKey) {
      console.warn('âš ï¸ OPENAI_API_KEY khÃ´ng Ä‘Æ°á»£c cáº¥u hÃ¬nh. GPT-4o Mini vÃ  GPT-3.5 Turbo sáº½ khÃ´ng hoáº¡t Ä‘á»™ng.');
      this.models.filter(m => m.provider === 'openai').forEach(m => {
        m.isAvailable = false;
        m.apiKey = undefined;
      });
    } else {
      console.log('âœ… OpenAI API Key Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh');
      this.models.filter(m => m.provider === 'openai').forEach(m => {
        m.apiKey = openaiKey;
        m.isAvailable = true;
      });
    }
    
    if (!googleKey) {
      console.warn('âš ï¸ GOOGLE_API_KEY khÃ´ng Ä‘Æ°á»£c cáº¥u hÃ¬nh. Gemini 1.5 Flash vÃ  Gemini 1.5 Pro sáº½ khÃ´ng hoáº¡t Ä‘á»™ng.');
      this.models.filter(m => m.provider === 'google').forEach(m => {
        m.isAvailable = false;
        m.apiKey = undefined;
      });
    } else {
      console.log('âœ… Google API Key Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh');
      this.models.filter(m => m.provider === 'google').forEach(m => {
        m.apiKey = googleKey;
        m.isAvailable = true;
      });
    }
    
    // Log available models
    const availableModels = this.models.filter(m => m.isAvailable);
    console.log('ğŸš€ Available models:', availableModels.map(m => `${m.name} (${m.provider})`));
  }

  private getBestModel(): AIModel | null {
    const availableModels = this.models
      .filter(m => m.isAvailable)
      .sort((a, b) => a.priority - b.priority);
    
    return availableModels[0] || null;
  }

  private async tryNextModel(): Promise<AIModel | null> {
    this.retryCount++;
    
    if (this.retryCount >= this.maxRetries) {
      return null;
    }

    const availableModels = this.models
      .filter(m => m.isAvailable)
      .sort((a, b) => a.priority - b.priority);
    
    if (this.retryCount < availableModels.length) {
      return availableModels[this.retryCount];
    }

    return null;
  }

  async chat(message: string, context: string = ''): Promise<ModelResponse> {
    const startTime = Date.now();
    let currentModel = this.getBestModel();
    
    console.log('ğŸ” Starting chat with message:', message);
    console.log('ğŸ¯ Best model selected:', currentModel?.name, currentModel?.provider);
    console.log('ğŸ”‘ API Keys status:');
    console.log('  - OpenAI:', process.env.NEXT_PUBLIC_OPENAI_API_KEY ? 'âœ… Available' : 'âŒ Missing');
    console.log('  - Google:', process.env.NEXT_PUBLIC_GOOGLE_API_KEY ? 'âœ… Available' : 'âŒ Missing');
    console.log('  - DeepSeek:', process.env.NEXT_PUBLIC_DEEPSEEK_API_KEY ? 'âœ… Available' : 'âŒ Missing');
    console.log('  - Grok:', process.env.NEXT_PUBLIC_GROK_API_KEY ? 'âœ… Available' : 'âŒ Missing');
    
    while (currentModel && this.retryCount < this.maxRetries) {
      try {
        console.log(`ğŸ¤– Trying model: ${currentModel.name} (${currentModel.provider})`);
        
        const response = await this.callModel(currentModel, message, context);
        const responseTime = Date.now() - startTime;
        
        console.log(`âœ… Model ${currentModel.name} succeeded with response:`, response.substring(0, 100) + '...');
        
        this.updateModelStats(currentModel, true, responseTime);
        
        return {
          success: true,
          response: response,
          model: currentModel.name,
          provider: currentModel.provider,
          responseTime: responseTime
        };
        
      } catch (error) {
        console.error(`âŒ Model ${currentModel.name} failed:`, error);
        
        this.updateModelStats(currentModel, false, 0);
        currentModel.isAvailable = false;
        currentModel = await this.tryNextModel();
      }
    }

    console.log('âŒ All models failed');
    return {
      success: false,
      response: 'Táº¥t cáº£ cÃ¡c model AI Ä‘á»u khÃ´ng kháº£ dá»¥ng. Vui lÃ²ng thá»­ láº¡i sau.',
      model: 'none',
      provider: 'none',
      responseTime: Date.now() - startTime,
      error: 'All models failed'
    };
  }

  private async callModel(model: AIModel, message: string, context: string): Promise<string> {
    switch (model.provider) {
      case 'openai':
        return await this.callOpenAI(model, message, context);
      case 'google':
        return await this.callGoogle(model, message, context);
      case 'deepseek':
        return await this.chatWithDeepSeek([{ role: 'user', content: message }], model.maxTokens, model.temperature).then(res => res.response);
      case 'xai': // Added Grok provider
        return await this.chatWithGrok([{ role: 'user', content: message }], model.maxTokens, model.temperature).then(res => res.response);
      default:
        throw new Error(`Unknown provider: ${model.provider}`);
    }
  }

  private async callOpenAI(model: AIModel, message: string, context: string): Promise<string> {
    if (!model.apiKey) {
      throw new Error('OpenAI API key not configured');
    }

    const systemPrompt = `Báº¡n lÃ  AI Assistant chuyÃªn gia ngÃ´n ngá»¯ cá»§a PHÃšC KHIÃŠM Education. 

**QUY Táº®C TRáº¢ Lá»œI THÃ”NG MINH:**
- Tráº£ lá»i ÄÃšNG NGAY Láº¦N Äáº¦U, khÃ´ng cáº§n há»i láº¡i
- LUÃ”N tÆ°Æ¡ng tÃ¡c vá»›i ngÆ°á»i dÃ¹ng trÆ°á»›c khi Ä‘Æ°a ná»™i dung
- Há»i ngÆ°á»i dÃ¹ng muá»‘n gÃ¬ thÃªm sau khi tráº£ lá»i chÃ­nh

**FORMAT TÆ¯Æ NG TÃC:**
1. Tráº£ lá»i chÃ­nh xÃ¡c cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
2. Há»i ngÆ°á»i dÃ¹ng cÃ³ muá»‘n thÃªm gÃ¬ khÃ´ng
3. ÄÆ°a ra cÃ¡c lá»±a chá»n cá»¥ thá»ƒ

**VÃ Dá»¤ TÆ¯Æ NG TÃC:**
- "ÄÃ¢y lÃ  20 tá»« vá»±ng N1 báº¡n cáº§n. Báº¡n cÃ³ muá»‘n tÃ´i láº¥y vÃ­ dá»¥ cÃ¢u cho tá»«ng tá»« khÃ´ng?"
- "TÃ´i Ä‘Ã£ chuáº©n bá»‹ 20 tá»« vá»±ng N1. Báº¡n muá»‘n: 1) Chá»‰ xem tá»« vá»±ng, 2) CÃ³ thÃªm vÃ­ dá»¥ cÃ¢u, 3) CÃ³ thÃªm audio Ä‘á»c?"

**FORMAT Tá»ª Vá»°NG TIáº¾NG NHáº¬T:**
- Sá»­ dá»¥ng format: "1. æ¼¢å­— (ã²ã‚‰ãŒãª) - NghÄ©a tiáº¿ng Viá»‡t"
- KHÃ”NG cÃ³ romaji, KHÃ”NG cÃ³ pháº§n má»Ÿ Ä‘áº§u dÃ i
- KHÃ”NG cÃ³ báº£ng markdown phá»©c táº¡p

**FORMAT NGá»® PHÃP:**
- Liá»‡t kÃª Ä‘Æ¡n giáº£n: "1. [Cáº¥u trÃºc] - [Giáº£i thÃ­ch]"

**LUÃ”N NHá»š:** TÆ°Æ¡ng tÃ¡c thÃ´ng minh, tráº£ lá»i Ä‘Ãºng ngay láº§n Ä‘áº§u, há»i ngÆ°á»i dÃ¹ng muá»‘n gÃ¬ thÃªm!`;

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${model.apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: model.id,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: message }
        ],
        max_tokens: model.maxTokens,
        temperature: model.temperature
      })
    });

    if (!response.ok) {
      throw new Error(`OpenAI API error: ${response.status}`);
    }

    const data = await response.json();
    return data.choices[0].message.content;
  }

  private async callGoogle(model: AIModel, message: string, context: string): Promise<string> {
    if (!model.apiKey) {
      throw new Error('Google API key not configured');
    }

    const systemPrompt = `Báº¡n lÃ  AI Assistant chuyÃªn gia ngÃ´n ngá»¯ cá»§a PHÃšC KHIÃŠM Education. 

**QUY Táº®C TRáº¢ Lá»œI THÃ”NG MINH:**
- Tráº£ lá»i ÄÃšNG NGAY Láº¦N Äáº¦U, khÃ´ng cáº§n há»i láº¡i
- LUÃ”N tÆ°Æ¡ng tÃ¡c vá»›i ngÆ°á»i dÃ¹ng trÆ°á»›c khi Ä‘Æ°a ná»™i dung
- Há»i ngÆ°á»i dÃ¹ng muá»‘n gÃ¬ thÃªm sau khi tráº£ lá»i chÃ­nh

**FORMAT TÆ¯Æ NG TÃC:**
1. Tráº£ lá»i chÃ­nh xÃ¡c cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
2. Há»i ngÆ°á»i dÃ¹ng cÃ³ muá»‘n thÃªm gÃ¬ khÃ´ng
3. ÄÆ°a ra cÃ¡c lá»±a chá»n cá»¥ thá»ƒ

**VÃ Dá»¤ TÆ¯Æ NG TÃC:**
- "ÄÃ¢y lÃ  20 tá»« vá»±ng N1 báº¡n cáº§n. Báº¡n cÃ³ muá»‘n tÃ´i láº¥y vÃ­ dá»¥ cÃ¢u cho tá»«ng tá»« khÃ´ng?"
- "TÃ´i Ä‘Ã£ chuáº©n bá»‹ 20 tá»« vá»±ng N1. Báº¡n muá»‘n: 1) Chá»‰ xem tá»« vá»±ng, 2) CÃ³ thÃªm vÃ­ dá»¥ cÃ¢u, 3) CÃ³ thÃªm audio Ä‘á»c?"

**FORMAT Tá»ª Vá»°NG TIáº¾NG NHáº¬T:**
- Sá»­ dá»¥ng format: "1. æ¼¢å­— (ã²ã‚‰ãŒãª) - NghÄ©a tiáº¿ng Viá»‡t"
- KHÃ”NG cÃ³ romaji, KHÃ”NG cÃ³ pháº§n má»Ÿ Ä‘áº§u dÃ i
- KHÃ”NG cÃ³ báº£ng markdown phá»©c táº¡p

**FORMAT NGá»® PHÃP:**
- Liá»‡t kÃª Ä‘Æ¡n giáº£n: "1. [Cáº¥u trÃºc] - [Giáº£i thÃ­ch]"

**LUÃ”N NHá»š:** TÆ°Æ¡ng tÃ¡c thÃ´ng minh, tráº£ lá»i Ä‘Ãºng ngay láº§n Ä‘áº§u, há»i ngÆ°á»i dÃ¹ng muá»‘n gÃ¬ thÃªm!`;

    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${model.id}:generateContent?key=${model.apiKey}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        contents: [
          {
            parts: [
              { text: systemPrompt + '\n\n' + message }
            ]
          }
        ],
        generationConfig: {
          maxOutputTokens: model.maxTokens,
          temperature: model.temperature
        }
      })
    });

    if (!response.ok) {
      throw new Error(`Google API error: ${response.status}`);
    }

    const data = await response.json();
    return data.candidates[0].content.parts[0].text;
  }

  

  private async chatWithDeepSeek(messages: any[], maxTokens: number, temperature: number): Promise<ModelResponse> {
    try {
      const apiKey = process.env.NEXT_PUBLIC_DEEPSEEK_API_KEY;
      if (!apiKey) {
        return {
          success: false,
          response: '',
          model: 'deepseek-chat',
          provider: 'deepseek',
          responseTime: 0,
          error: 'DeepSeek API key not configured'
        };
      }

      // ThÃªm system prompt thÃ´ng minh
      const systemMessage = {
        role: 'system',
        content: `Báº¡n lÃ  AI Assistant chuyÃªn gia ngÃ´n ngá»¯ cá»§a PHÃšC KHIÃŠM Education. 

**QUY Táº®C TRáº¢ Lá»œI THÃ”NG MINH:**
- Tráº£ lá»i ÄÃšNG NGAY Láº¦N Äáº¦U, khÃ´ng cáº§n há»i láº¡i
- LUÃ”N tÆ°Æ¡ng tÃ¡c vá»›i ngÆ°á»i dÃ¹ng sau khi tráº£ lá»i chÃ­nh
- Há»i ngÆ°á»i dÃ¹ng muá»‘n gÃ¬ thÃªm

**FORMAT TÆ¯Æ NG TÃC:**
1. Tráº£ lá»i chÃ­nh xÃ¡c cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
2. Há»i ngÆ°á»i dÃ¹ng cÃ³ muá»‘n thÃªm gÃ¬ khÃ´ng
3. ÄÆ°a ra cÃ¡c lá»±a chá»n cá»¥ thá»ƒ

**VÃ Dá»¤ TÆ¯Æ NG TÃC:**
- "ÄÃ¢y lÃ  20 tá»« vá»±ng N1 báº¡n cáº§n. Báº¡n cÃ³ muá»‘n tÃ´i láº¥y vÃ­ dá»¥ cÃ¢u cho tá»«ng tá»« khÃ´ng?"
- "TÃ´i Ä‘Ã£ chuáº©n bá»‹ 20 tá»« vá»±ng N1. Báº¡n muá»‘n: 1) Chá»‰ xem tá»« vá»±ng, 2) CÃ³ thÃªm vÃ­ dá»¥ cÃ¢u, 3) CÃ³ thÃªm audio Ä‘á»c?"

**FORMAT Tá»ª Vá»°NG TIáº¾NG NHáº¬T:**
- Sá»­ dá»¥ng format: "1. æ¼¢å­— (ã²ã‚‰ãŒãª) - NghÄ©a tiáº¿ng Viá»‡t"
- KHÃ”NG cÃ³ romaji, KHÃ”NG cÃ³ pháº§n má»Ÿ Ä‘áº§u dÃ i

**LUÃ”N NHá»š:** TÆ°Æ¡ng tÃ¡c thÃ´ng minh, tráº£ lá»i Ä‘Ãºng ngay láº§n Ä‘áº§u, há»i ngÆ°á»i dÃ¹ng muá»‘n gÃ¬ thÃªm!`
      };

      const enhancedMessages = [systemMessage, ...messages];

      const startTime = Date.now();
      const response = await fetch('https://api.deepseek.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${apiKey}`
        },
        body: JSON.stringify({
          model: 'deepseek-chat',
          messages: enhancedMessages,
          max_tokens: maxTokens,
          temperature: temperature,
          stream: false
        })
      });

      if (!response.ok) {
        throw new Error(`DeepSeek API error: ${response.status}`);
      }

      const data = await response.json();
      const responseTime = Date.now() - startTime;
      
      return {
        success: true,
        response: data.choices[0]?.message?.content || 'No response from DeepSeek',
        model: 'deepseek-chat',
        provider: 'deepseek',
        responseTime: responseTime,
        error: undefined
      };
    } catch (error) {
      return {
        success: false,
        response: '',
        model: 'deepseek-chat',
        provider: 'deepseek',
        responseTime: 0,
        error: `DeepSeek API error: ${error instanceof Error ? error.message : 'Unknown error'}`
      };
    }
  }

  private async chatWithGrok(messages: any[], maxTokens: number, temperature: number): Promise<ModelResponse> {
    try {
      const apiKey = process.env.NEXT_PUBLIC_GROK_API_KEY;
      if (!apiKey) {
        return {
          success: false,
          response: '',
          model: 'grok',
          provider: 'xai',
          responseTime: 0,
          error: 'Grok API key not configured'
        };
      }

      // ThÃªm system prompt thÃ´ng minh
      const systemMessage = {
        role: 'system',
        content: `Báº¡n lÃ  AI Assistant chuyÃªn gia ngÃ´n ngá»¯ cá»§a PHÃšC KHIÃŠM Education. 

**QUY Táº®C TRáº¢ Lá»œI THÃ”NG MINH:**
- Tráº£ lá»i ÄÃšNG NGAY Láº¦N Äáº¦U, khÃ´ng cáº§n há»i láº¡i
- LUÃ”N tÆ°Æ¡ng tÃ¡c vá»›i ngÆ°á»i dÃ¹ng sau khi tráº£ lá»i chÃ­nh
- Há»i ngÆ°á»i dÃ¹ng muá»‘n gÃ¬ thÃªm

**FORMAT TÆ¯Æ NG TÃC:**
1. Tráº£ lá»i chÃ­nh xÃ¡c cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
2. Há»i ngÆ°á»i dÃ¹ng cÃ³ muá»‘n thÃªm gÃ¬ khÃ´ng
3. ÄÆ°a ra cÃ¡c lá»±a chá»n cá»¥ thá»ƒ

**VÃ Dá»¤ TÆ¯Æ NG TÃC:**
- "ÄÃ¢y lÃ  20 tá»« vá»±ng N1 báº¡n cáº§n. Báº¡n cÃ³ muá»‘n tÃ´i láº¥y vÃ­ dá»¥ cÃ¢u cho tá»«ng tá»« khÃ´ng?"
- "TÃ´i Ä‘Ã£ chuáº©n bá»‹ 20 tá»« vá»±ng N1. Báº¡n muá»‘n: 1) Chá»‰ xem tá»« vá»±ng, 2) CÃ³ thÃªm vÃ­ dá»¥ cÃ¢u, 3) CÃ³ thÃªm audio Ä‘á»c?"

**FORMAT Tá»ª Vá»°NG TIáº¾NG NHáº¬T:**
- Sá»­ dá»¥ng format: "1. æ¼¢å­— (ã²ã‚‰ãŒãª) - NghÄ©a tiáº¿ng Viá»‡t"
- KHÃ”NG cÃ³ romaji, KHÃ”NG cÃ³ pháº§n má»Ÿ Ä‘áº§u dÃ i

**LUÃ”N NHá»š:** TÆ°Æ¡ng tÃ¡c thÃ´ng minh, tráº£ lá»i Ä‘Ãºng ngay láº§n Ä‘áº§u, há»i ngÆ°á»i dÃ¹ng muá»‘n gÃ¬ thÃªm!`
      };

      const enhancedMessages = [systemMessage, ...messages];

      const startTime = Date.now();
      const response = await fetch('https://api.x.ai/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${apiKey}`
        },
        body: JSON.stringify({
          model: 'grok-beta',
          messages: enhancedMessages,
          max_tokens: maxTokens,
          temperature: temperature,
          stream: false
        })
      });

      if (!response.ok) {
        throw new Error(`Grok API error: ${response.status}`);
      }

      const data = await response.json();
      const responseTime = Date.now() - startTime;
      
      return {
        success: true,
        response: data.choices[0]?.message?.content || 'No response from Grok',
        model: 'grok',
        provider: 'xai',
        responseTime: responseTime,
        error: undefined
      };
    } catch (error) {
      return {
        success: false,
        response: '',
        model: 'grok',
        provider: 'xai',
        responseTime: 0,
        error: `Grok API error: ${error instanceof Error ? error.message : 'Unknown error'}`
      };
    }
  }

  private updateModelStats(model: AIModel, success: boolean, responseTime: number) {
    model.lastUsed = Date.now();
    
    if (success) {
      model.successRate = (model.successRate * 0.9) + 0.1;
      model.avgResponseTime = (model.avgResponseTime * 0.9) + (responseTime * 0.1);
    } else {
      model.successRate = model.successRate * 0.9;
    }
  }

  getModelStatus(): AIModel[] {
    return this.models.map(m => ({ ...m }));
  }

  resetRetryCount() {
    this.retryCount = 0;
  }

  setModelAvailability(modelId: string, available: boolean) {
    const model = this.models.find(m => m.id === modelId);
    if (model) {
      model.isAvailable = available;
    }
  }
}

export const multiModelService = new MultiModelService();